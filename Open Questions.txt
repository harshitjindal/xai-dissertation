Open questions:
2. Check what each leaf node of the decision tree means
3. Why do we have (OBS = 0) in the decision tree visualization?
4. How to handle numeric scaling with visualization of decision tree?
5. Maybe try applying LIME and SHAP to inherently explainable models like LR
6. What type of problem statements can EBM used for?
7. LIME/SHAP on CNN/RNN/LSTM models?
8. What does LIME and SHAP outputs look like for other models such as CNNs and GANs?
9. RNN vs LSTM
10. Why would anyone want to use EBM when we can use DL models like RF and apply LIME/SHAP to it? What benefit does EBM have over the alternative?

Things to include:
- certificate from handout
- mentor evaluation
- ppt
- pdf of report
- plag report
- code (optional)
